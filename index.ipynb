{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Resizing, Input, Normalization\n",
    "from keras.models import Sequential\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We donwload and extract required dataset using `pathlib` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = 'data/'\n",
    "\n",
    "data_dir = pathlib.Path(DATASET_PATH)\n",
    "\n",
    "tf.keras.utils.get_file(\n",
    "    'voicedataset.zip',\n",
    "    origin='http://aiolearn.com/dl/datasets/voicedata.zip',\n",
    "    extract=True,\n",
    "    cache_dir='.',\n",
    "    cache_subdir='data'\n",
    ")\n",
    "\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right',\n",
       " 'voicedataset.zip',\n",
       " 'go',\n",
       " 'no',\n",
       " 'left',\n",
       " 'stop',\n",
       " 'README.md',\n",
       " 'up',\n",
       " 'down',\n",
       " 'yes']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.gfile.listdir(str(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Commands:  ['right' 'go' 'no' 'left' 'stop' 'up' 'down' 'yes']\n"
     ]
    }
   ],
   "source": [
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "\n",
    "commands = commands[(commands != 'README.md') & (commands != 'voicedataset.zip')]\n",
    "\n",
    "print('Available Commands: ', commands )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 8 classes.\n",
      "Using 6400 files for training.\n",
      "Using 1600 files for validation.\n",
      "\n",
      "label :  ['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = tf.keras.utils.audio_dataset_from_directory(directory=data_dir,\n",
    "                                                              batch_size=64,\n",
    "                                                              validation_split=0.2,\n",
    "                                                              seed=0,\n",
    "                                                              output_sequence_length=16000,\n",
    "                                                              subset='both')\n",
    "\n",
    "label_names = np.array(X_train.class_names)\n",
    "print()\n",
    "print('label : ', label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we mix and merge the sound and its label with the `squeeze` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels\n",
    "\n",
    "X_train = X_train.map(squeeze, tf.data.AUTOTUNE)\n",
    "X_test = X_test.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 16000), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
